#!/bin/sh  
exec $HBASE_HOME/bin/hbase shell <<EOF  
create 'test', {NAME => 't', VERSIONS => 1}  
EOF  
2.bin/hbase shell,这个就是常用的shell工具，运维常用的DDL和DML都会通过此进行，其具体实现（对hbase的调用）是用ruby写的
3.bin/hbase hbck, 运维常用工具，检查集群的数据一致性状态，其执行是直接调用org.apache.hadoop.hbase.util.HBaseFsck中的main函数
4.bin/hbase hlog, log分析工具，其执行是直接调用org.apache.hadoop.hbase.regionserver.wal.HLogPrettyPrinter中的main函数
5.bin/hbase hfile， hfile分析工具，其执行是直接调用org.apache.hadoop.hbase.io.hfile.HFile中的main函数
6.bin/hbase zkcli,查看/管理ZK的shell工具，很实用，经常用，比如你可以通过（get /IP/master）其得知当前的active master,可以通过（get /IP/root-region-server）得知当前root region所在的server，你也可以在测试中通过（delete /IP/rs/dwxx.yy.taobao），模拟regionserver与ZK断开连接，
其执行则是调用了org.apache.zookeeper.ZooKeeperMain的main函数
7.bin/hbase classpath 打印classpath
8.bin/hbase version 打印hbase版本信息
===============
首先，编写一个文本文件firsthbaseshell.txt：

status 查看状态
version 查看版本
list
list 'abc.*' #显示abc开头的表
describe 'table_name'
scan 'ns1:t1',{COLUMNS=>['c1','c2'],LIMIT=>10,STARTROW=>'xyz'}

 create 'test', 'col', SPLITS => ['user1', 'user2','user3','user4','user5','user6','user7','user8','user9',]
create 'test', 'cf'  
list 'test'  
put 'test', 'row1', 'cf:a', 'value1'
scan 'test'  
get 'test', 'row1'  
disable 'test'  
enable 'test'
exit
2、在HBase shell中运行这个脚本：
利用命令：hbase shell firstbaseshell.txt:

更改表名

//快照 这样试试，先建立个表自己测试下，可以的话在执行。

需要开启快照功能，在hbase-site.xml文件中添加如下配置项：
<property>
<name>hbase.snapshot.enabled</name>
<value>true</value>
</property>
//命令
hbase shell> disable 'tableName'
hbase shell> snapshot 'tableName', 'tableSnapshot'
hbase shell> clone_snapshot 'tableSnapshot', 'newTableName'
hbase shell> delete_snapshot 'tableSnapshot'
hbase shell> drop 'tableName'
================================

HBASE按单个Rowkey检索的效率是很高的，耗时在1毫秒以下，每秒钟可获取1000~2000条记录，不过非key列的查询很慢。

HBase的RowKey设计
    Rowkey长度原则：Rowkey是一个二进制码流，Rowkey的长度被很多开发者建议说设计在10~100个字节，
	                不过建议是越短越好，不要超过16个字节。
             （1）数据的持久化文件HFile中是按照KeyValue存储的，如果Rowkey过长比如100个字节，
                  1000万列数据光Rowkey就要占用100*1000万=10亿个字节，将近1G数据，这会极大影响HFile的存储效率；
             
             （2）MemStore将缓存部分数据到内存，如果Rowkey字段过长内存的有效利用率会降低，系统将无法缓存更多的数据，
		          这会降低检索效率。因此Rowkey的字节长度越短越好。
             
             （3）目前操作系统是都是64位系统，内存8字节对齐。控制在16个字节，8字节的整数倍利用操作系统的最佳特性。
   
   Rowkey散列原则：如果Rowkey是按时间戳的方式递增，不要将时间放在二进制码的前面，建议将Rowkey的高位作为散列字段，由程序循环生成，
                   低位放时间字段，这样将提高数据均衡分布在每个Regionserver实现负载均衡的几率。如果没有散列字段，首字段直接是时间
				   信息将产生所有新数据都在一个 RegionServer上堆积的热点现象，这样在做数据检索的时候负载将会集中在个别RegionServer，降低查询效率。
    Rowkey唯一原则：必须在设计上保证其唯一性。
   
   HBase按指定的条件获取一批记录时，使用的就是scan方法。 scan方法有以下特点：

                （1）scan可以通过setCaching与setBatch方法提高速度（以空间换时间）；
                （2）scan可以通过setStartRow与setEndRow来限定范围。范围越小，性能越高。
                     通过巧妙的RowKey设计使我们批量获取记录集合中的元素挨在一起（应该在同一个Region下），可以在遍历结果时获得很好的性能。
                （3）scan可以通过setFilter方法添加过滤器，这也是分页、多条件查询的基础。
                
                在满足长度、三列、唯一原则后，我们需要考虑如何通过巧妙设计RowKey以利用scan方法的范围功能，使得获取一批记录的查询速度能提高。
                下例就描述如何将多个列组合成一个RowKey，使用scan的range来达到较快查询速度。
     
   

集群数据倾斜
   在集群中为了得到更好的并行性，我们希望有好的load blance，让每个节点提供的请求都是均衡的，我们也不希望，region不要经常split，
因为split会使server有一段时间的停顿，如何能做到呢？
    随机散列与预分区二者结合起来，是比较完美的。预分区一开始就预建好了一部分region，这些region都维护着自己的start-end keys，
在配合上随机散列，写数据能均衡的命中这些预建的region，就能解决上面的那些缺点，大大提供性能。





balance_switch true 开启负载均衡

手动触发major compaction
Region管理
1）移动region
# 语法：move 'encodeRegionName', 'ServerName'
# encodeRegionName指的regioName后面的编码，ServerName指的是master-status的Region Servers列表
# 示例
hbase(main)>move '4343995a58be8e5bbc739af1e91cd72d', 'db-41.xxx.xxx.org,60020,1390274516739'



#语法：
#Compact all regions in a table:
#hbase> major_compact 't1'
#Compact an entire region:
#hbase> major_compact 'r1'
#Compact a single column family within a region:
#hbase> major_compact 'r1', 'c1'
#Compact a single column family within a table:
#hbase> major_compact 't1', 'c1'

 开启/关闭region
# 语法：balance_switch true|false
hbase(main)> balance_switch

 手动split
# 语法：split 'regionName', 'splitKey'



在逻辑上，HBase的表数据按RowKey进行字典排序， RowKey实际上是数据表的一级索引（Primary Index），
由于HBase本身没有二级索引（Secondary Index）机制，基于索引检索数据只能单纯地依靠RowKey，为了能支持多条件查询，
开发者需要将所有可能作为查询条件的字段一一拼接到RowKey中，这是HBase开发中极为常见的做法，但是无论怎样设计，
单一RowKey固有的局限性决定了它不可能有效地支持多条件查询。  
通常来说，RowKey只能针对条件中含有其首字段的查询给予令人满意的性能支持，在查询其他字段时，表现就差强人意了，
在极端情况下某些字段的查询性能可能会退化为全表扫描的水平，这是因为字段在RowKey中的地位是不等价的，
它们在RowKey中的排位决定了它们被检索时的性能表现，排序越靠前的字段在查询中越具有优势，特别是首位字段具有特别的先发优势，
如果查询中包含首位字段，检索时就可以通过首位字段的值确定RowKey的前缀部分，从而大幅度地收窄检索区间，
如果不包含则只能在全体数据的RowKey上逐一查找，由此可以想见两者在性能上的差距。 

hbase(main):024:0>status
3 servers, 0 dead,1.0000 average load

hbase(main):025:0>version
0.90.4, r1150278,Sun Jul 24 15:53:29 PDT 2011

我们之前建了3个列族，但是发现member_id这个列族是多余的，因为他就是主键，所以我们要将其删除。
hbase(main):003:0>alter 'member',{NAME=>'member_id',METHOD=>'delete'}

ERROR: Table memberis enabled. Disable it first before altering.

报错，删除列族的时候必须先将表给disable掉。
hbase(main):004:0>disable 'member'                                  
0 row(s) in 2.0390seconds
hbase(main):005:0>alter'member',NAME=>'member_id',METHOD=>'delete'
0 row(s) in 0.0560seconds
hbase(main):006:0>describe 'member'
DESCRIPTION                                                                                          ENABLED                                               
{NAME => 'member', FAMILIES => [{NAME=> 'address', BLOOMFILTER => 'NONE', REPLICATION_SCOPE => '0',false                                                 
  VERSIONS => '3', COMPRESSION => 'NONE',TTL => '2147483647', BLOCKSIZE => '65536', IN_MEMORY => 'fa                                                       
lse', BLOCKCACHE => 'true'}, {NAME =>'info', BLOOMFILTER => 'NONE', REPLICATION_SCOPE => '0', VERSI                                                       
ONS => '3', COMPRESSION => 'NONE', TTL=> '2147483647', BLOCKSIZE => '65536', IN_MEMORY => 'false',                                                        
BLOCKCACHE => 'true'}]}                                                                                                                                    
1 row(s) in 0.0230seconds
该列族已经删除，我们继续将表enable
hbase(main):008:0> enable 'member'  
0 row(s) in 2.0420seconds


6.查询表是否存在
hbase(main):021:0>exists 'member'
Table member doesexist  


判断表是否disable
hbase(main):032:0>is_disabled 'member'
false                                                                                                                                                       
0 row(s) in 0.0110seconds

6.删除整行
hbase(main):001:0>deleteall 'member','xiaofeng'
0 row(s) in 0.3990seconds

查询表中有多少行：
hbase(main):019:0>count 'member'                                        
2 row(s) in 0.0160seconds




========================
===============================
每个regionserver节点可以自由启动或停止，可以不随hbase整体一起。
停止后regionserver上的数据会被移到其他regionserver上，不影响hbase的使用

重启regionserver
bin/graceful_stop.sh --restart --reload --debug nodename

启动regionserver
/bin/hbase-daemon.sh start regionserver RegionServer

Hbase作为列族数据库最经常被人诟病的特性包括：无法轻易建立“二级索引”，难以执行求和、计数、排序等操作。
比如，在旧版本的(<0.92)Hbase中，统计数据表的总行数，需要使用Counter方法，执行一次MapReduce Job才能得到。
虽然HBase在数据存储层中集成了MapReduce，能够有效用于数据表的分布式计算。然而在很多情况下，
做一些简单的相加或者聚合计算的时候，如果直接将计算过程放置在server端能够减少通讯开销，从而获得很好的性能提升。
于是，HBase在0.92之后引入了协处理器(coprocessors)，
实现一些激动人心的新特性：能够轻易建立二次索引、复杂过滤器(谓词下推)以及访问控制等。


CoprocessorRowcounter已经在实践中统计了我们大部分表的行数，正确性也经过了验证，存在的问题主要是资源占用率过高，
不宜用于在线集群。其次效率仍需提高，即使能够对region进行并发操作，大表的统计仍需要分钟级甚至是小时级的耗时。
实践也发现每次rpc调用时间都比正常操作长很多，所以务必将hbase.rpc.timeout设置为Integer.MAX_VALUE，
才能保证程序不会因为rpc超时而退出。

实现hbase表的行数统计工作：
1.count命令
最直接的方式是在hbase shell中执行count的命令可以统计行数。
[html] view plain copy
hbase> count ‘t1′  
hbase> count ‘t1′, INTERVAL => 100000  
hbase> count ‘t1′, CACHE => 1000  
hbase> count ‘t1′, INTERVAL => 10, CACHE => 1000  
其中，INTERVAL为统计的行数间隔，默认为1000，CACHE为统计的数据缓存。这种方式效率很低，如果表行数很大的话不建议采用这种方式。
2. 调用Mapreduce
[plain] view plain copy
$HBASE_HOME/bin/hbase   org.apache.hadoop.hbase.mapreduce.RowCounter ‘tablename’  
这种方式效率比上一种要搞很多，调用的hbase jar中自带的统计行数的类。

3.hive over hbase
如果已经见了hive和hbase的关联表的话，可以直接在hive中执行sql语句统计hbase表的行数。
hive over hbase 表的建表语句为：
/*创建hive与hbase的关联表*/
[sql] view plain copy
CREATE TABLE hive_hbase_1(key INT,value STRING)  
STORED BY 'org.apache.hadoop.hive.hbase.HBaseStorageHandler'  
WITH SERDEPROPERTIES ("hbase.columns.mapping"=":key,cf:val")  
TBLPROPERTIES("hbase.table.name"="t_hive","hbase.table.default.storage.type"="binary");  
/*hive关联已经存在的hbase*/
[sql] view plain copy
CREATE EXTERNAL TABLE hive_hbase_1(key INT,value STRING)  
STORED BY 'org.apache.hadoop.hive.hbase.HBaseStorageHandler'  
WITH SERDEPROPERTIES ("hbase.columns.mapping"=":key,cf:val")  
TBLPROPERTIES("hbase.table.name"="t_hive","hbase.table.default.storage.type"="binary");


4.1启用协处理器 Aggregation(Enable Coprocessor Aggregation)
我们有两个方法：1.启动全局aggregation，能过操纵所有的表上的数据。通过修改hbase-site.xml这个文件来实现，只需要添加如下代码：

<property>
   <name>hbase.coprocessor.user.region.classes</name>
   <value>org.apache.hadoop.hbase.coprocessor.AggregateImplementation</value>
 </property>
2.启用表aggregation，只对特定的表生效。通过HBase Shell 来实现。

(1)disable指定表。hbase> disable 'mytable'

(2)添加aggregation hbase> alter 'mytable', METHOD => 'table_att','coprocessor'=>'|org.apache.Hadoop.hbase.coprocessor.AggregateImplementation||'

(3)重启指定表 hbase> enable 'mytable'

4.2统计行数代码(Code Snippet)
public class MyAggregationClient { 

private static final byte[] TABLE_NAME = Bytes.toBytes("mytable");
private static final byte[] CF = Bytes.toBytes("vent");
public static void main(String[] args) throws Throwable {
Configuration customConf = new Configuration();
customConf.setStrings("hbase.zookeeper.quorum",
"node0,node1,node2");
//提高RPC通信时长
customConf.setLong("hbase.rpc.timeout", 600000);
//设置Scan缓存
customConf.setLong("hbase.client.scanner.caching", 1000);
Configuration configuration = HBaseConfiguration.create(customConf);
AggregationClient aggregationClient = new AggregationClient(
configuration);
Scan scan = new Scan();
//指定扫描列族，唯一值
scan.addFamily(CF);
long rowCount = aggregationClient.rowCount(TABLE_NAME, null, scan);
System.out.println("row count is " + rowCount);

}
}





=======
=================
4.3 典型例子
  协处理器其中的一个作用是使用Observer创建二级索引。先举个实际例子： 
  我们要查询指定店铺指定客户购买的订单，首先有一张订单详情表，它以被处理后的订单id作为rowkey；
  其次有一张以客户nick为rowkey的索引表，结构如下： 

rowkey family 
dp_id+buy_nick1 tid1:null tid2:null ... 
dp_id+buy_nick2 tid3:null 
... 
该表可以通过Coprocessor来构建，实例代码： 
[html] view plain copy 在CODE上查看代码片派生到我的代码片
public class TestCoprocessor extends BaseRegionObserver {   
    @Override   
     public void prePut(final ObserverContext<RegionCoprocessorEnvironment> e,   
     final Put put, final WALEdit edit, final boolean writeToWAL)   
     throws IOException {   
         Configuration conf = new Configuration();   
         HTable table = new HTable(conf, "index_table");   
         List<KeyValue> kv = put.get("data".getBytes(), "name".getBytes());   
         Iterator<KeyValue> kvItor = kv.iterator();   
         while (kvItor.hasNext()) {   
             KeyValue tmp = kvItor.next();   
             Put indexPut = new Put(tmp.getValue());   
             indexPut.add("index".getBytes(), tmp.getRow(), Bytes.toBytes(System.currentTimeMillis()));   
             table.put(indexPut);   
         }   
         table.close();   
     }   
}   

即继承BaseRegionObserver类，实现prePut方法，在插入订单详情表之前，向索引表插入索引数据

4.4索引表的使用 
先在索引表get索引表，获取tids，然后根据tids查询订单详情表。 
当有多个查询条件（多张索引表），根据逻辑运算符（and 、or）确定tids。 
4.5使用时注意 

1.索引表是一张普通的hbase表，为安全考虑需要开启Hlog记录日志。 
2.索引表的rowkey最好是不可变量，避免索引表中产生大量的脏数据。 
3.如上例子，column是横向扩展的（宽表），rowkey设计除了要考虑region均衡，也要考虑column数量，即表不要太宽。建议不超过3位数。 
4.如上代码，一个put操作其实是先后向两张表put数据，为保证一致性，需要考虑异常处理，建议异常时重试。 

4.6效率情况 

put操作效率不高，如上代码，每插入一条数据需要创建一个新的索引表连接（可以使用htablepool优化），向索引表插入数据。即耗时是双倍的，对hbase的集群的压力也是双倍的。当索引表有多个时，压力会更大。 
查询效率比filter高，毫秒级别，因为都是rowkey的查询。 
如上是估计的效率情况，需要根据实际业务场景和集群情况而定，最好做预先测试。 
4.7Coprocessor二级索引方案优劣 

优点：在put压力不大、索引region均衡的情况下，查询很快。 
缺点：业务性比较强，若有多个字段的查询，需要建立多张索引表，需要保证多张表的数据一致性，
且在hbase的存储和内存上都会有更高的要求。

============
========================
要想看到hfile内容的文本化版本，你可以使用org.apache.hadoop.hbase.io.hfile.HFile 工具。可以这样用：

$ ${HBASE_HOME}/bin/hbase org.apache.hadoop.hbase.io.hfile.HFile  
例如，你想看文件 hdfs://10.81.47.41:9000/hbase/TEST/1418428042/DSMP/4759508618286845475的内容, 就执行如下的命令:

 $ ${HBASE_HOME}/bin/hbase org.apache.hadoop.hbase.io.hfile.HFile -v -f hdfs://10.81.47.41:9000/hbase/TEST/1418428042/DSMP/4759508618286845475  
如果你没有输入-v,就仅仅能看到一个hfile的汇总信息。其他功能的用法可以看HFile的文档。



