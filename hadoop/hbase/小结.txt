
===============


更改表名

//快照 这样试试，先建立个表自己测试下，可以的话在执行。

需要开启快照功能，在hbase-site.xml文件中添加如下配置项：
<property>
<name>hbase.snapshot.enabled</name>
<value>true</value>
</property>
//命令
hbase shell> disable 'tableName'
hbase shell> snapshot 'tableName', 'tableSnapshot'
hbase shell> clone_snapshot 'tableSnapshot', 'newTableName'
hbase shell> delete_snapshot 'tableSnapshot'
hbase shell> drop 'tableName'
================================

balance_switch true 开启负载均衡
 开启/关闭region
# 语法：balance_switch true|false
hbase(main)> balance_switch






0 row(s) in 0.0110seconds





========================
===============================





4.2统计行数代码(Code Snippet)
public class MyAggregationClient { 

private static final byte[] TABLE_NAME = Bytes.toBytes("mytable");
private static final byte[] CF = Bytes.toBytes("vent");
public static void main(String[] args) throws Throwable {
Configuration customConf = new Configuration();
customConf.setStrings("hbase.zookeeper.quorum",
"node0,node1,node2");
//提高RPC通信时长
customConf.setLong("hbase.rpc.timeout", 600000);
//设置Scan缓存
customConf.setLong("hbase.client.scanner.caching", 1000);
Configuration configuration = HBaseConfiguration.create(customConf);
AggregationClient aggregationClient = new AggregationClient(
configuration);
Scan scan = new Scan();
//指定扫描列族，唯一值
scan.addFamily(CF);
long rowCount = aggregationClient.rowCount(TABLE_NAME, null, scan);
System.out.println("row count is " + rowCount);

}
}





=======
=================
4.3 典型例子
  协处理器其中的一个作用是使用Observer创建二级索引。先举个实际例子： 
  我们要查询指定店铺指定客户购买的订单，首先有一张订单详情表，它以被处理后的订单id作为rowkey；
  其次有一张以客户nick为rowkey的索引表，结构如下： 

rowkey family 
dp_id+buy_nick1 tid1:null tid2:null ... 
dp_id+buy_nick2 tid3:null 
... 
该表可以通过Coprocessor来构建，实例代码： 
[html] view plain copy 在CODE上查看代码片派生到我的代码片
public class TestCoprocessor extends BaseRegionObserver {   
    @Override   
     public void prePut(final ObserverContext<RegionCoprocessorEnvironment> e,   
     final Put put, final WALEdit edit, final boolean writeToWAL)   
     throws IOException {   
         Configuration conf = new Configuration();   
         HTable table = new HTable(conf, "index_table");   
         List<KeyValue> kv = put.get("data".getBytes(), "name".getBytes());   
         Iterator<KeyValue> kvItor = kv.iterator();   
         while (kvItor.hasNext()) {   
             KeyValue tmp = kvItor.next();   
             Put indexPut = new Put(tmp.getValue());   
             indexPut.add("index".getBytes(), tmp.getRow(), Bytes.toBytes(System.currentTimeMillis()));   
             table.put(indexPut);   
         }   
         table.close();   
     }   
}   

即继承BaseRegionObserver类，实现prePut方法，在插入订单详情表之前，向索引表插入索引数据

4.4索引表的使用 
先在索引表get索引表，获取tids，然后根据tids查询订单详情表。 
当有多个查询条件（多张索引表），根据逻辑运算符（and 、or）确定tids。 
4.5使用时注意 

1.索引表是一张普通的hbase表，为安全考虑需要开启Hlog记录日志。 
2.索引表的rowkey最好是不可变量，避免索引表中产生大量的脏数据。 
3.如上例子，column是横向扩展的（宽表），rowkey设计除了要考虑region均衡，也要考虑column数量，即表不要太宽。建议不超过3位数。 
4.如上代码，一个put操作其实是先后向两张表put数据，为保证一致性，需要考虑异常处理，建议异常时重试。 

4.6效率情况 

put操作效率不高，如上代码，每插入一条数据需要创建一个新的索引表连接（可以使用htablepool优化），向索引表插入数据。即耗时是双倍的，对hbase的集群的压力也是双倍的。当索引表有多个时，压力会更大。 
查询效率比filter高，毫秒级别，因为都是rowkey的查询。 
如上是估计的效率情况，需要根据实际业务场景和集群情况而定，最好做预先测试。 
4.7Coprocessor二级索引方案优劣 

优点：在put压力不大、索引region均衡的情况下，查询很快。 
缺点：业务性比较强，若有多个字段的查询，需要建立多张索引表，需要保证多张表的数据一致性，
且在hbase的存储和内存上都会有更高的要求。

============
========================
要想看到hfile内容的文本化版本，你可以使用org.apache.hadoop.hbase.io.hfile.HFile 工具。可以这样用：

$ ${HBASE_HOME}/bin/hbase org.apache.hadoop.hbase.io.hfile.HFile  
例如，你想看文件 hdfs://10.81.47.41:9000/hbase/TEST/1418428042/DSMP/4759508618286845475的内容, 就执行如下的命令:

 $ ${HBASE_HOME}/bin/hbase org.apache.hadoop.hbase.io.hfile.HFile -v -f hdfs://10.81.47.41:9000/hbase/TEST/1418428042/DSMP/4759508618286845475  
如果你没有输入-v,就仅仅能看到一个hfile的汇总信息。其他功能的用法可以看HFile的文档。



