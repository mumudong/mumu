一个 Hadoop HDFS Datanode 有一个同时处理文件的上限. 这个参数叫 xcievers (Hadoop的作者把这个单词拼错了). 在你加载之前，先确认下你有没有配置这个文件conf/hdfs-site.xml里面的xceivers参数，至少要有4096:

      <property>
        <name>dfs.datanode.max.xcievers</name>
        <value>4096</value>
      </property>



dfs.datanode.handler.count----DN的服务线程数，接收请求
dfs.namenode.handler.count---加大NN的服务线程数，用于处理RPC请求


很多hadoop用户经常迷惑hadoop fsck，hadoop fs -dus，hadoop -count -q等hadoop文件系统命令输出的大小以及意义。
这里对这类问题做一个小结。首先我们来明确2个概念：

逻辑空间，即分布式文件系统上真正的文件大小
物理空间，即存在分布式文件系统上该文件实际占用的空间
为什么逻辑空间一般不等于物理空间？
分布式文件系统为了保证文件的可靠性，往往会保存多个备份（一般是3份)，只要备份数不为1的情况下，一般物理空间会是逻辑空间的几倍。关系如下：

HDFS物理空间=逻辑空间*block备份数
hadoop fsck和hadoop fs -dus 
执行hadoop fsck和hadoop fs -dus显示的文件大小表示的是文件占用的逻辑空间。

$ hadoop fsck /path/to/directory
 Total size:    16565944775310 B    <=== 看这里
 Total dirs:    3922
 Total files:   418464
 Total blocks (validated):      502705 (avg. block size 32953610 B)
 Minimally replicated blocks:   502705 (100.0 %)
 Over-replicated blocks:        0 (0.0 %)
 Under-replicated blocks:       0 (0.0 %)
 Mis-replicated blocks:         0 (0.0 %)
 Default replication factor:    3
 Average block replication:     3.0
 Corrupt blocks:                0
 Missing replicas:              0 (0.0 %)
 Number of data-nodes:          18
 Number of racks:               1
FSCK ended at Thu Oct 20 20:49:59 CET 2011 in 7516 milliseconds
 
The filesystem under path '/path/to/directory' is HEALTHY

$ hadoop fs -dus /path/to/directory
hdfs://master:54310/path/to/directory        16565944775310    <=== 看这里
正如命令示例所见，hadoop fsck和hadoop fs -dus报告的文件大小都是HDFS文件实际占用的大小，即这个空间大小是没有算块的备份数的。文件真正占用的物理空间=逻辑空间block备份数据，即16565944775310 3=49697834325930，这个49697834325930是物理空间。

hadoop fs -count -q 
通过执行hadoop fs -count -q /path/to/directory 可以看到这个目录真正的空间使用情况。执行结果如下:

fs -count -q会输出8列，分别表示如下:

命名空间的quota（限制文件数）	剩余的命名空间quota	物理空间的quota （限制空间占用大小）	剩余的物理空间	目录数统计	文件数统计	目录逻辑空间总大小	路径
可以看出通过hadoop fs -count -q 可以看到一个目录比较详细的空间和qutoa占用情况，包含了物理空间、逻辑空间、文件数、目录数、qutoa剩余量等。



执行fsck /
hadoop fsck / > fsck.out
确认丢失的块
grep 'MISSING' fsck.out











=====
=========
================




hadoop checknative

文件空间限制quota
hadoop fs -count -q /user/sjzx_b
hadoop dfsadmin -clrSpaceQuota /user/fenriswolf/
hadoop dfsadmin -setQuota 大小 /user/fenriswolf



输出datanode状态
     hdfs dfsadmin -report
输出serverid状态
     hdfs haadmin -getServiceState nn1
切换namenode	 
     hdfs  haadmin -failover --forcefence --forceactive  nn2  nn1  切换到nn1
查看计算节点状态
     yarn node -list
查看hbase状态	 
     hbase shell status
查看zookeeper状态
     zkServer.sh status
impala-shell << FOE
show databases;
FOE

查看hive是否完好
    ps -ef |grep hive
检查文件丢失    
    hdfs fsck /

动态增加hbasse节点
    hbase-daemon.sh start regionserver

for i in `hadoop job -list | grep -w  username| awk '{print $1}' | grep job_`; 
    do hadoop job -kill $i;
done

看空间使用情况：
执行hadoop fsck和hadoop fs -dus显示的文件大小表示的是文件占用的逻辑空间
可以看出通过hadoop fs -count -q 可以看到一个目录比较详细的空间和qutoa占用情况，
包含了物理空间、逻辑空间、文件数、目录数、qutoa剩余量等。
$ hadoop fsck /path/to/directory
hadoop fsck和hadoop fs -dus
$ hadoop fs -count -q /path/to/directory

确认Hadoop中丢失的文件
hadoop fsck / > fsck.out
grep 'MISSING' fsck.out

查看资源队列
    hadoop queue -list

 第二部分：MapReduce作业管理
命令行工具
• 查看 Job 信息
•      hadoop job -list
• 杀掉 Job
•      hadoop  job –kill
        yarn application -kill application_1497248309313_0493
•指定路径下查看历史日志汇总
•      hadoop job -history output-dir
$      bin/hadoop job -history all output-dir
•作业的更多细节
•       hadoop job -history all output-dir
•打印map和reduce完成百分比和所有计数器
•       hadoop job –status job_id
•杀死任务。被杀死的任务不会不利于失败尝试。
•       hadoop jab -kill-task <task-id>
•使任务失败。被失败的任务会对失败尝试不利。
        •hadoop job  -fail-task <task-id>
        -list [all]     -list all         显示所有作业。-list只显示将要完成的作业。
        -kill-task <task-id>               杀死任务。被杀死的任务不会不利于失败尝试。
        -fail-task <task-id>              使任务失败。被失败的任务会对
Hadoop mradmin
命令

列出Jobtracer上所有的作业
    hadoop job -list
使用hadoop job -kill杀掉指定的jobid
    hadoop job -kill job_id

组合以上两条命令就可以实现kill掉指定用户的job
for i in `hadoop job -list | grep -w  username| awk '{print $1}' | grep job_`; 
     do hadoop job -kill $i; 
done



说明
-refreshServiceAcl
重新装载ACL认证文件

-Hadoop mradmin  -refreshQueues	
刷新任务队列的信息
-refreshUserToGroupsMappings	
刷新用户与用户组对应关系
-refreshSuperUserGroupsConfiguration
刷新用户组的配置
-refreshNodes	
刷新JobTracker的主机配置信息 
15、使Datanode节点 datanodename退役   
  $ bin/hadoop dfsadmin -decommission datanodename
18、在升级之前，管理员需要用（升级终结操作）命令删除存在的备份文件
$ bin/hadoop dfsadmin -finalizeUpgrade
19、能够知道是否需要对一个集群执行升级终结操作。
  $ dfsadmin -upgradeProgress status
20、使用-upgrade选项运行新的版本
  $ bin/start-dfs.sh -upgrade
21、如果需要退回到老版本,就必须停止集群并且部署老版本的Hadoop，用回滚选项启动集群
  $ bin/start-dfs.h -rollback

28、打印版本信息。
 用法：hadoop version
29、hadoop脚本可用于调调用任何类。
 用法：hadoop CLASSNAME
            运行名字为CLASSNAME的类。
30、运行集群平衡工具。管理员可以简单的按Ctrl-C来停止平衡过程(balancer)
 用法：hadoop balancer [-threshold <threshold>]
命令选项                             描述
-threshold <threshold>                     磁盘容量的百分比。这会覆盖缺省的阀值。

Hadoop查看目录文件大小的脚本
hadoop fs -du /user/sjzx_b/data/get_data/ | awk '{ sum=$1 ;dir2=$3 ; hum[1024**3]="Gb";hum[1024**2]="Mb";hum[1024]="Kb"; for (x=1024**3; x>=1024; x/=1024){ if (sum>=x) { printf "%.2f %s \t %s\n",sum/x,hum[x],dir2;break } }}'
查看指定目录下各子目录包含的目录数和文件数
awk 'BEGIN{while(("Hadoop fs -ls /group/tmp/" | getline) >0){var = "hadoop fs -count "$8; system(var); }}' | sort -rk 1 | cat > shaka.dat 